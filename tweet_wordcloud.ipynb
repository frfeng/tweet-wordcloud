{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet word cloud \n",
    "\n",
    "### Generating a word cloud in the shape of a Twitter logo based on a user's tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running the code, you need to:\n",
    "\n",
    "1. Have a Twitter account. If not, you can sign up at https://twitter.com\n",
    "\n",
    "\n",
    "2. Apply for a Twitter developer account. You can appy at https://developer.twitter.com\n",
    "\n",
    "\n",
    "3. Create an app at https://developer.twitter.com/en/apps. Then in the **Keys and tokens** tab, get your Twitter credentials (consumer key, consumer secret, access token, and access token secret) .\n",
    "\n",
    "\n",
    "4. Edit the file `keys.py` and add your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import keys\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate with Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(keys.consumer_key, \n",
    "                           keys.consumer_secret)\n",
    "\n",
    "auth.set_access_token(keys.access_token,\n",
    "                     keys.access_token_secret)\n",
    "\n",
    "# create an API object\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,\n",
    "                wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set the user of interest\n",
    "twitter_handle = 'um_dearborn'\n",
    "\n",
    "# specificy the time window of the tweets by using tweet IDs\n",
    "# You can find a tweet's ID from its web URL, e.g., https://twitter.com/UM_Dearborn/status/1079954125616566272\n",
    "# Currently, I don't know a better way to specify the time window\n",
    "\n",
    "# The example below retrieves all the tweets by @um_dearborn in 2019 \n",
    "# by using the ID of its last tweet in 2018 (since_id) and last tweets in 2019 (max_id).\n",
    "\n",
    "since_id = 1079954125616566272  # Returns results with an ID greater than (that is, more recent than) the specified ID.\n",
    "\n",
    "max_id = 1212044012389044228    # Returns only statuses with an ID less than (that is, older than) or equal to the specified ID.\n",
    "\n",
    "# create a Cursor object for the user_timeline method\n",
    "cursor = tweepy.Cursor(api.user_timeline, \n",
    "                       screen_name=twitter_handle, \n",
    "                       since_id=since_id,\n",
    "                       max_id=max_id,\n",
    "                       include_rts=False,\n",
    "                       tweet_mode='extended')\n",
    "\n",
    "# put the retrieved tweets in a list\n",
    "tweets = []\n",
    "\n",
    "for tweet in cursor.items():\n",
    "    tweets.append(tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stop words (using nltk)\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "# add some additional custom stop words\n",
    "# make sure they are all in lower case\n",
    "additional_stops = {\"’\", \"’\", \"“\", \"”\", \"'s\", \"n't\", \"'m\", \"'re\", \"'ll\", \"rt\", \"i.e\", \"amp\"}\n",
    "stops.update(additional_stops)\n",
    "\n",
    "tweet_words = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    # remove mentions\n",
    "    tweet = re.sub('@[^\\s]+', '', tweet)\n",
    "    # remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    # remove stop words\n",
    "    tweet_words.extend([word for word in TextBlob(tweet).words if word.lower() not in stops])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data directory\n",
    "d = os.path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "\n",
    "# read the mask image\n",
    "mask = np.array(Image.open(os.path.join(d, \"twitter_mask.png\")))  \n",
    "\n",
    "# configure the word cloud\n",
    "wordcloud = WordCloud(width=1600, height=900,\n",
    "                      colormap='viridis',         # you can choose other matplotlib colormaps\n",
    "                      background_color='white', \n",
    "                      mask=mask)\n",
    "\n",
    "# generate the word cloud\n",
    "wordcloud = wordcloud.generate(' '.join(tweet_words))\n",
    "\n",
    "# store to file\n",
    "wordcloud = wordcloud.to_file('tweet_wordcloud.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
